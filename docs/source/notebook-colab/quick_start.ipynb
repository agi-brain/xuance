{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Quick Start\n",
    "\n",
    "## Run a DRL example\n",
    "\n",
    "In XuanCe, it is easy to build a DRL agent.\n",
    "First you need to create a *runner* and specify the ``agent_name``, ``env_name``,\n",
    "then a runner that contains agent, policy, and envs, etc., will be built.\n",
    "Finally, execute ``runner.run()`` and the agent's model is training.\n",
    "\n",
    "To get started, install XuanCe first.\n",
    "\n",
    "(Note: --quiet is optional and only suppresses output in Google Colab; it's not required for installing XuanCe)"
   ],
   "metadata": {
    "id": "fdLOhBhlt_by"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install xuance --quiet"
   ],
   "metadata": {
    "id": "004dbUyvNULE",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "outputId": "8e4d0c85-0aed-41f1-a4d0-15ceb6c0b500"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import xuance\n",
    "runner = xuance.get_runner(method='ppo',\n",
    "                           env='classic_control',\n",
    "                           env_id='CartPole-v1',\n",
    "                           is_test=False)\n",
    "runner.run()"
   ],
   "metadata": {
    "id": "-LtiBijbgVJO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "To modify the hyperparameters in the example above, create a namespace that specifies the configuration, like this:"
   ],
   "metadata": {
    "id": "H62iPPOxgX1u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import xuance\n",
    "from argparse import Namespace\n",
    "\n",
    "parser = Namespace(method=\"ppo\", env=\"classic_control\", env_id=\"CartPole-v1\", test=False, device=\"cpu\")\n",
    "runner = xuance.get_runner(method=parser.method,\n",
    "                           env=parser.env,\n",
    "                           env_id=parser.env_id,\n",
    "                           parser_args=parser,\n",
    "                           is_test=parser.test)\n",
    "runner.run()"
   ],
   "metadata": {
    "id": "8KHo-DQegZ9Y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run an MARL example\n",
    "\n",
    "XuanCe support MARL algorithms with both cooperative and competitive tasks.\n",
    "Similaly, you can start by:"
   ],
   "metadata": {
    "id": "GQYBjw2Sgh79"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import xuance\n",
    "runner = xuance.get_runner(method='maddpg',\n",
    "                           env='mpe',\n",
    "                           env_id='simple_spread_v3',\n",
    "                           is_test=False)\n",
    "runner.run()"
   ],
   "metadata": {
    "id": "K6u4SCmvgkAh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "For competitve tasks in which agents can be divided to two or more sides, you can run a demo by:"
   ],
   "metadata": {
    "id": "efksMolpglib"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import xuance\n",
    "runner = xuance.get_runner(method=[\"maddpg\", \"iddpg\"],\n",
    "                           env='mpe',\n",
    "                           env_id='simple_push_v3',\n",
    "                           is_test=False)\n",
    "runner.run()"
   ],
   "metadata": {
    "id": "WC8gMKFTgnqT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this demo, the agents in [mpe/simple_push](https://pettingzoo.farama.org/environments/mpe/simple_push) environment are divided into two sides, named \"adversary_0\" and \"agent_0\".\n",
    "The \"adversary\"s are MADDPG agents, and the \"agent\"s are IDDPG agents.\n",
    "\n",
    "## Test\n",
    "\n",
    "After completing the algorithm training, XuanCe will save the model files and training log information in the designated directory.\n",
    "Users can specify \"is_test=True\" to perform testing."
   ],
   "metadata": {
    "id": "kNHAilhAgquE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import xuance\n",
    "runner = xuance.get_runner(method='ppo',\n",
    "                           env='classic_control',\n",
    "                           env_id='CartPole-v1',\n",
    "                           is_test=True)\n",
    "runner.run()"
   ],
   "metadata": {
    "id": "EpF2aH94gvF8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above code, \"runner.benchmark()\" can also be used instead of \"runner.run()\" to train benchmark models and obtain benchmark test results.\n",
    "\n",
    "## Logger\n",
    "\n",
    "You can use the tensorboard or wandb to visualize the training process by specifying the \"logger\" parameter in the \"xuance/configs/basic.yaml\".\n",
    "\n",
    "\n",
    "```yaml\n",
    "logger: tensorboard\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```yaml\n",
    "logger: wandb\n",
    "```\n",
    "\n",
    "**1. Tensorboard**\n",
    "\n",
    "After completing the model training, the log files are stored in the \"log\" folder in the root directory.\n",
    "The specific path depends on the user's actual configuration.\n",
    "Taking the path \"./logs/dqn/torch/CartPole-v0\" as an example, users can visualize the logs using the following command:\n"
   ],
   "metadata": {
    "id": "WEHh3AX8g0xX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!tensorboard --logdir ./logs/ppo/torch/CartPole-v1/ --port 6006"
   ],
   "metadata": {
    "id": "ZlQ_hAL5hE9C"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we can see the training curves at http://localhost:6006/.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../_static/figures/log/tensorboard.png\" width=\"auto\" height=\"auto\" align=center />\n",
    "</div>\n",
    "\n",
    "**2. W&B**\n",
    "\n",
    "If you choose to use the wandb tool for training visualization,\n",
    "you can create an account according to the official W&B instructions and specify the username \"wandb_user_name\" in the \"xuance/configs/basic.yaml\" file.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../_static/figures/log/wandb.png\" width=\"auto\" height=\"auto\" align=center />\n",
    "</div>\n",
    "\n",
    "For information on using W&B and its local deployment, you can refer to the following link:\n",
    "\n",
    "**wandb**: [https://github.com/wandb/wandb.git](https://github.com/wandb/wandb.git)\n",
    "\n",
    "**wandb server**: [https://github.com/wandb/server.git](https://github.com/wandb/server.git)"
   ],
   "metadata": {
    "id": "yoGcNPO2hPys"
   }
  }
 ]
}
