<div align="center">
<img src="docs/source/_static/figures/logo_1.png" width="480" height="auto" align=center />
</div>

# XuanCe: ä¸€ä¸ªå…¨é¢ä¸”ç»Ÿä¸€çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“

[![PyPI](https://img.shields.io/pypi/v/xuance)](https://pypi.org/project/xuance/)
[![Documentation Status](https://readthedocs.org/projects/xuance/badge/?version=latest)](https://xuance.readthedocs.io)
[![GitHub](https://img.shields.io/github/license/agi-brain/xuance)](https://github.com/agi-brain/xuance/blob/master/LICENSE.txt)
[![Downloads](https://static.pepy.tech/badge/xuance)](https://pepy.tech/project/xuance)
[![GitHub Repo stars](https://img.shields.io/github/stars/agi-brain/xuance?style=social)](https://github.com/agi-brain/xuance/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/agi-brain/xuance?style=social)](https://github.com/agi-brain/xuance/forks)
[![GitHub watchers](https://img.shields.io/github/watchers/agi-brain/xuance?style=social)](https://github.com/agi-brain/xuance/watchers)

[![PyTorch](https://img.shields.io/badge/PyTorch-%3E%3D1.13.0-red)](https://pytorch.org/get-started/locally/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-%3E%3D2.6.0-orange)](https://www.tensorflow.org/install)
[![MindSpore](https://img.shields.io/badge/MindSpore-%3E%3D1.10.1-blue)](https://www.mindspore.cn/install/en)

[![Python](https://img.shields.io/badge/Python-3.7%7C3.8%7C3.9%7C3.10-yellow)](https://www.anaconda.com/download)
[![gym](https://img.shields.io/badge/gym-%3E%3D0.21.0-blue)](https://www.gymlibrary.dev/)
[![gymnasium](https://img.shields.io/badge/gymnasium-%3E%3D0.28.1-blue)](https://www.gymlibrary.dev/)
[![pettingzoo](https://img.shields.io/badge/PettingZoo-%3E%3D1.23.0-blue)](https://pettingzoo.farama.org/)

**[README.md](README.md)**
|**[è‹±æ–‡æ–‡æ¡£](https://xuance.readthedocs.io/en/latest/)**
| **[ä¸­æ–‡æ–‡æ¡£](https://xuance.readthedocs.io/zh/latest/)**

**XuanCe** æ˜¯ä¸€ä¸ªå¼€æºçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰ç®—æ³•åº“ã€‚

æˆ‘ä»¬å°†å…¶ç§°ä¸º **Xuan-Ceï¼ˆç„ç­–ï¼‰**ã€‚
â€œ**ç„ï¼ˆXuanï¼‰**â€å¯“æ„ç„å¦™çš„ï¼Œâ€œ**ç­–ï¼ˆCeï¼‰**â€æ„ä¸ºç­–ç•¥ã€‚

ç”±äº DRL ç®—æ³•é€šå¸¸å¯¹è¶…å‚æ•°æ•æ„Ÿã€æ•ˆæœæ˜“éšæŠ€å·§ï¼ˆtricksï¼‰çš„ä¸åŒè€Œå·®å¼‚è¾ƒå¤§ï¼Œè®­ç»ƒè¿‡ç¨‹æœ¬èº«ä¹Ÿä¸å¤Ÿç¨³å®šï¼Œå› æ­¤ DRL ç®—æ³•æœ‰æ—¶æ˜¾å¾—éš¾ä»¥æ‰æ‘¸ï¼Œå¸¦æœ‰â€œç„å­¦â€çš„æ„å‘³ã€‚æœ¬é¡¹ç›®è‡´åŠ›äºæä¾›æ·±å…¥ã€ä¼˜è´¨ã€æ˜“æ‡‚çš„ DRL ç®—æ³•å®ç°ï¼Œå¸Œæœ›èƒ½æ­ç¤ºå¼ºåŒ–å­¦ä¹ ä¸­è¿™äº›â€œç„å­¦â€èƒŒåçš„åŸç†ã€‚

æˆ‘ä»¬æœŸæœ›å®ƒèƒ½å…¼å®¹å¤šç§æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆ**[PyTorch](https://pytorch.org/)**ã€**[TensorFlow](https://www.tensorflow.org/)** å’Œ **[MindSpore](https://www.mindspore.cn/en)**ï¼‰ï¼Œå¹¶å¸Œæœ›å®ƒèƒ½å¤Ÿæˆä¸ºæ¶µç›–å¤šç§ DRL ç®—æ³•çš„æ™ºèƒ½å†³ç­–æ¡†æ¶ã€‚

è®ºæ–‡é“¾æ¥ï¼š[https://arxiv.org/pdf/2312.16248.pdf](https://arxiv.org/pdf/2312.16248.pdf)

ç›®å½•ï¼š
- [**é¡¹ç›®ç‰¹æ€§**](#features-of-xuance)
- [**å·²å®ç°ç®—æ³•**](#currently-included-algorithms)
- [**å·²æ”¯æŒç¯å¢ƒ**](#currently-supported-environments)
- [**å®‰è£…æ–¹æ³•**](#point_right-installation)
- [**å¿«é€Ÿä¸Šæ‰‹**](#point_right-quickly-start)
- [**ç¤¾åŒºäº¤æµ**](#community)
- [**å¼•ç”¨**](#citations)

## ä¸ºä»€ä¹ˆé€‰æ‹© XuanCeï¼Ÿ

### XuanCe çš„ç‰¹æ€§

- :school_satchel: é«˜åº¦æ¨¡å—åŒ–è®¾è®¡ã€‚
- :thumbsup: æ˜“äº[å­¦ä¹ ](https://xuance.readthedocs.io/en/latest/)ï¼Œæ˜“äº[å®‰è£…](https://xuance.readthedocs.io/en/latest/documents/usage/installation.html)ï¼Œæ˜“äº[ä½¿ç”¨](https://xuance.readthedocs.io/en/latest/documents/usage/basic_usage.html)ã€‚
- :twisted_rightwards_arrows: æ¨¡å‹ç»„åˆçµæ´»ã€‚
- :tada: æä¾›å¤§é‡[ç®—æ³•](https://xuance.readthedocs.io/en/latest/#list-of-algorithms)åŠå¤šç§ä»»åŠ¡æ”¯æŒã€‚
- :couple: åŒæ—¶æ”¯æŒ DRL å’Œ MARLï¼ˆå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼‰ä»»åŠ¡ã€‚
- :key: é«˜åº¦å…¼å®¹ä¸åŒç”¨æˆ·éœ€æ±‚ã€‚ï¼ˆPyTorchã€TensorFlow2ã€MindSporeã€CPUã€GPUã€Linuxã€Windowsã€MacOS ç­‰ï¼‰
- :zap: æ”¯æŒç¯å¢ƒå¹¶è¡Œï¼Œè¿è¡Œé€Ÿåº¦å¿«ã€‚
- :computer: æ”¯æŒå¤š GPU åˆ†å¸ƒå¼è®­ç»ƒã€‚
- ğŸ›ï¸ æ”¯æŒè‡ªåŠ¨åŒ–è¶…å‚æ•°è°ƒä¼˜ã€‚
- :chart_with_upwards_trend: ä¸ [tensorboard](https://www.tensorflow.org/tensorboard) æˆ– [wandb](https://wandb.ai/site) å·¥å…·ç»“åˆï¼Œå…·å¤‡è‰¯å¥½å¯è§†åŒ–æ•ˆæœã€‚

## å·²å®ç°ç®—æ³•

### :point_right: DRL

- **DQN**: Deep Q Network [[è®ºæ–‡](https://www.nature.com/articles/nature14236)]
- **Double DQN**: DQN with Double Q-learning [[è®ºæ–‡](https://ojs.aaai.org/index.php/AAAI/article/view/10295)]
- **Dueling DQN**: DQN with Dueling Network [[è®ºæ–‡](http://proceedings.mlr.press/v48/wangf16.pdf)]
- **PER**: DQN with Prioritized Experience Replay [[è®ºæ–‡](https://arxiv.org/pdf/1511.05952.pdf)]
- **NoisyDQN**: DQN with Parameter Space Noise for Exploration [[è®ºæ–‡](https://arxiv.org/pdf/1706.01905.pdf)]
- **DRQN**: Deep Recurrent Q-Netwrk [[è®ºæ–‡](https://cdn.aaai.org/ocs/11673/11673-51288-1-PB.pdf)]
- **QRDQN**: DQN with Quantile Regression [[è®ºæ–‡](https://ojs.aaai.org/index.php/AAAI/article/view/11791)]
- **C51**: Distributional Reinforcement Learning [[è®ºæ–‡](http://proceedings.mlr.press/v70/bellemare17a/bellemare17a.pdf)]
- **PG**: Vanilla Policy Gradient [[è®ºæ–‡](https://proceedings.neurips.cc/paper_files/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf)]
- **NPG**: Natural Policy Gradient [[è®ºæ–‡](https://proceedings.neurips.cc/paper_files/paper/2001/file/4b86abe48d358ecf194c56c69108433e-Paper.pdf)]
- **PPG**: Phasic Policy Gradient [[è®ºæ–‡](http://proceedings.mlr.press/v139/cobbe21a/cobbe21a.pdf)] [[æºç ](https://github.com/openai/phasic-policy-gradient)]
- **A2C**: Advantage Actor Critic [[è®ºæ–‡](http://proceedings.mlr.press/v48/mniha16.pdf)] [[æºç ](https://github.com/openai/baselines/tree/master/baselines/a2c)]
- **SAC**: Soft Actor-Critic [[è®ºæ–‡](http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf)] [[æºç ](http://github.com/haarnoja/sac)]
- **SAC-Discrete**: Soft Actor-Critic for Discrete Actions [[è®ºæ–‡](https://arxiv.org/pdf/1910.07207.pdf)] [[æºç ](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch)]
- **PPO-Clip**: Proximal Policy Optimization with Clipped Objective [[è®ºæ–‡](https://arxiv.org/pdf/1707.06347.pdf)] [[æºç ]( https://github.com/berkeleydeeprlcourse/homework/tree/master/hw4)]
- **PPO-KL**: Proximal Policy Optimization with KL Divergence [[è®ºæ–‡](https://arxiv.org/pdf/1707.06347.pdf)] [[æºç ]( https://github.com/berkeleydeeprlcourse/homework/tree/master/hw4)]
- **DDPG**: Deep Deterministic Policy Gradient [[è®ºæ–‡](https://arxiv.org/pdf/1509.02971.pdf)] [[æºç ](https://github.com/openai/baselines/tree/master/baselines/ddpg)]
- **TD3**: Twin Delayed Deep Deterministic Policy Gradient [[è®ºæ–‡](http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf)][[æºç ](https://github.com/sfujim/TD3)]
- **P-DQN**: Parameterised Deep Q-Network [[è®ºæ–‡](https://arxiv.org/pdf/1810.06394.pdf)]
- **MP-DQN**: Multi-pass Parameterised Deep Q-network [[è®ºæ–‡](https://arxiv.org/pdf/1905.04388.pdf)] [[æºç ](https://github.com/cycraig/MP-DQN)]
- **SP-DQN**: Split Parameterised Deep Q-Network [[è®ºæ–‡](https://arxiv.org/pdf/1810.06394.pdf)]

### :point_right: Model-Based Reinforcement Learning (MBRL)

- **DreamerV2** [[è®ºæ–‡](https://openreview.net/pdf?id=0oabwyZbOu)] [[æºç ](https://github.com/danijar/dreamerv2.git)]
- **DreamerV3** [[è®ºæ–‡](https://www.nature.com/articles/s41586-025-08744-2.pdf)] [[æºç ](https://github.com/danijar/dreamerv3.git)]
- **HarmonyDream** [[è®ºæ–‡](https://proceedings.mlr.press/v235/ma24o.html)] [[æºç ](https://github.com/thuml/HarmonyDream.git)]

### :point_right: Multi-Agent Reinforcement Learning (MARL)

- **IQL**: Independent Q-learning [[è®ºæ–‡](https://hal.science/file/index/docid/720669/filename/Matignon2012independent.pdf)] [[æºç ](https://github.com/oxwhirl/pymarl)]
- **VDN**: Value Decomposition Networks [[è®ºæ–‡](https://arxiv.org/pdf/1706.05296.pdf)] [[æºç ](https://github.com/oxwhirl/pymarl)]
- **QMIX**: Q-mixing networks [[è®ºæ–‡](http://proceedings.mlr.press/v80/rashid18a/rashid18a.pdf)] [[æºç ](https://github.com/oxwhirl/pymarl)]
- **WQMIX**: Weighted Q-mixing networks [[è®ºæ–‡](https://proceedings.neurips.cc/paper/2020/file/73a427badebe0e32caa2e1fc7530b7f3-Paper.pdf)] [[æºç ](https://github.com/oxwhirl/wqmix)]
- **QTRAN**: Q-transformation [[è®ºæ–‡](http://proceedings.mlr.press/v97/son19a/son19a.pdf)] [[æºç ](https://github.com/Sonkyunghwan/QTRAN)]
- **DCG**: Deep Coordination Graphs [[è®ºæ–‡](http://proceedings.mlr.press/v119/boehmer20a/boehmer20a.pdf)] [[æºç ](https://github.com/wendelinboehmer/dcg)]
- **IDDPG**: Independent Deep Deterministic Policy Gradient [[è®ºæ–‡](https://proceedings.neurips.cc/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf)]
- **MADDPG**: Multi-agent Deep Deterministic Policy Gradient [[è®ºæ–‡](https://proceedings.neurips.cc/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf)] [[æºç ](https://github.com/openai/maddpg)]
- **IAC**: Independent Actor-Critic [[è®ºæ–‡](https://ojs.aaai.org/index.php/AAAI/article/view/11794)] [[æºç ](https://github.com/oxwhirl/pymarl)]
- **COMA**: Counterfactual Multi-agent Policy Gradient [[è®ºæ–‡](https://ojs.aaai.org/index.php/AAAI/article/view/11794)] [[æºç ](https://github.com/oxwhirl/pymarl)]
- **VDAC**: Value-Decomposition Actor-Critic [[è®ºæ–‡](https://ojs.aaai.org/index.php/AAAI/article/view/17353)] [[æºç ](https://github.com/hahayonghuming/VDACs.git)]
- **IPPO**: Independent Proximal Policy Optimization [[è®ºæ–‡](https://proceedings.neurips.cc/paper_files/paper/2022/file/9c1535a02f0ce079433344e14d910597-Paper-Datasets_and_Benchmarks.pdf)] [[æºç ](https://github.com/marlbenchmark/on-policy)]
- **MAPPO**: Multi-agent Proximal Policy Optimization [[è®ºæ–‡](https://proceedings.neurips.cc/paper_files/paper/2022/file/9c1535a02f0ce079433344e14d910597-Paper-Datasets_and_Benchmarks.pdf)] [[æºç ](https://github.com/marlbenchmark/on-policy)]
- **MFQ**: Mean-Field Q-learning [[è®ºæ–‡](http://proceedings.mlr.press/v80/yang18d/yang18d.pdf)] [[æºç ](https://github.com/mlii/mfrl)]
- **MFAC**: Mean-Field Actor-Critic [[è®ºæ–‡](http://proceedings.mlr.press/v80/yang18d/yang18d.pdf)] [[æºç ](https://github.com/mlii/mfrl)]
- **ISAC**: Independent Soft Actor-Critic
- **MASAC**: Multi-agent Soft Actor-Critic [[è®ºæ–‡](https://arxiv.org/pdf/2104.06655.pdf)]
- **MATD3**: Multi-agent Twin Delayed Deep Deterministic Policy Gradient [[è®ºæ–‡](https://arxiv.org/pdf/1910.01465.pdf)]
- **IC3Net**: Individualized Controlled Continuous Communication Model [[è®ºæ–‡](https://arxiv.org/pdf/1812.09755)] [[æºç ](https://github.com/IC3Net/IC3Net.git)]
- **CommNet**: Communication Neural Net [[Paper](https://proceedings.neurips.cc/paper_files/paper/2016/file/55b1927fdafef39c48e5b73b5d61ea60-Paper.pdf)][[æºç ](https://github.com/cts198859/deeprl_network.git)]
- **TarMAC**: Targeted Multi-Agent Communication [[Paper](https://proceedings.mlr.press/v97/das19a)]

### :point_right: Contrastive Reinforcement Learning (CRL)
- **CURL**: Contrastive Unsupervised Representation Learning for Sample-Efficient Reinforcement Learning [[Paper](http://proceedings.mlr.press/v119/laskin20a/laskin20a.pdf)] [[æºç ](https://github.com/MishaLaskin/curl/blob/master/curl_sac.py)]
- **SPR**: Data-Efficient Reinforcement Learning with Self-Predictive Representations [[Paper]](https://arxiv.org/abs/2007.05929) [[æºç ]](https://github.com/mila-iqia/spr)

## å·²æ”¯æŒç¯å¢ƒ

### [Classic Control](https://www.gymlibrary.dev/environments/classic_control/)

<details open>
<summary>ï¼ˆç‚¹å‡»æ”¶èµ·/å±•å¼€ï¼‰</summary>

<table rules="none" align="center"><tr>
<td> <center>
<img src="docs/source/_static/figures/classic_control/cart_pole.gif" height=100" /><br/><font color="AAAAAA">Cart Pole</font>
</center></td>
<td> <center>
<img src="docs/source/_static/figures/classic_control/pendulum.gif" height=100" /> <br/> <font color="AAAAAA">Pendulum</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/classic_control/acrobot.gif" height=100" /> <br/> <font color="AAAAAA">Acrobot</font>
</center> </td>
<td> <center>
<br/> <font color="AAAAAA">...</font>
</tr>
</table>

</details>

### [Box2D](https://www.gymlibrary.dev/environments/box2d/)

<details open>
<summary>ï¼ˆç‚¹å‡»æ”¶èµ·/å±•å¼€ï¼‰</summary>

<table rules="none" align="center"><tr>
<td> <center>
<img src="docs/source/_static/figures/box2d/bipedal_walker.gif" height=100" /><br/><font color="AAAAAA">Bipedal Walker</font>
</center></td>
<td> <center>
<img src="docs/source/_static/figures/box2d/car_racing.gif" height=100" /> <br/> <font color="AAAAAA">Car Racing</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/box2d/lunar_lander.gif" height=100" /> <br/> <font color="AAAAAA">Lunar Lander</font>
</center> </td>
</tr>
</table>

</details>

### [MuJoCo ç¯å¢ƒ](https://www.gymlibrary.dev/environments/mujoco/)

<details open>
<summary>ï¼ˆç‚¹å‡»æ”¶èµ·/å±•å¼€ï¼‰</summary>

<table rules="none" align="center"><tr>
<td> <center>
<img src="docs/source/_static/figures/mujoco/ant.gif" height=100" /><br/><font color="AAAAAA">Ant</font>
</center></td>
<td> <center>
<img src="docs/source/_static/figures/mujoco/half_cheetah.gif" height=100" /> <br/> <font color="AAAAAA">HalfCheetah</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/mujoco/hopper.gif" height=100" /> <br/> <font color="AAAAAA">Hopper</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/mujoco/humanoid.gif" height=100" /> <br/> <font color="AAAAAA">Humanoid</font>
</center> </td>
<td> <center>
<br/> <font color="AAAAAA">...</font>
</center> </td>
</tr>
</table>
</details>

### [Atari ç¯å¢ƒ](https://www.gymlibrary.dev/environments/atari/)

<details open>
<summary>ï¼ˆç‚¹å‡»æ”¶èµ·/å±•å¼€ï¼‰</summary>

<table rules="none" align="center"><tr>
<td> <center>
<img src="docs/source/_static/figures/atari/adventure.gif" height=100" /> <br/> <font color="AAAAAA">Adventure</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/atari/air_raid.gif" height=100" /> <br/> <font color="AAAAAA">Air Raid</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/atari/alien.gif" height=100" /> <br/> <font color="AAAAAA">Alien</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/atari/amidar.gif" height=100" /><br/><font color="AAAAAA">Amidar</font>
</center></td>
<td> <center>
<img src="docs/source/_static/figures/atari/assault.gif" height=100" /> <br/> <font color="AAAAAA">Assault</font>
</center> </td>
<td> <center>
<br/> <font color="AAAAAA">...</font>
</center> </td>
</tr>
</table>

</details>

### [Minigrid ç¯å¢ƒ](https://minigrid.farama.org/)

<details open>
<summary>ï¼ˆç‚¹å‡»æ”¶èµ·/å±•å¼€ï¼‰</summary>

<table rules="none" align="center"><tr>
<td> <center>
<img src="docs/source/_static/figures/minigrid/GoToDoorEnv.gif" height=100" /><br/><font color="AAAAAA">GoToDoorEnv</font>
</center></td>
<td> <center>
<img src="docs/source/_static/figures/minigrid/LockedRoomEnv.gif" height=100" /> <br/> <font color="AAAAAA">LockedRoomEnv</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/minigrid/MemoryEnv.gif" height=100" /> <br/> <font color="AAAAAA">MemoryEnv</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/minigrid/PlaygroundEnv.gif" height=100" /> <br/> <font color="AAAAAA">PlaygroundEnv</font>
</center> </td>
<td> <center>
<br/> <font color="AAAAAA">...</font>
</center> </td>
</tr>
</table>
</details>

### [æ— äººæœºç¯å¢ƒï¼ˆDrones Environmentsï¼‰](https://github.com/utiasDSL/gym-pybullet-drones)

å¯å‚è€ƒ [XuanCe æ–‡æ¡£ä¸­å…³äº gym-pybullet-drones çš„å®‰è£…ä¸ä½¿ç”¨è¯´æ˜](https://xuance.readthedocs.io/en/latest/documents/api/environments/drones.html)ã€‚

<details open>
<summary>ï¼ˆç‚¹å‡»æ”¶èµ·/å±•å¼€ï¼‰</summary>

<table rules="none" align="center"><tr>
<td> <center>
<img src="docs/source/_static/figures/drones/helix.gif" height=100" /><br/><font color="AAAAAA">Helix</font>
</center></td>
<td> <center>
<img src="docs/source/_static/figures/drones/rl.gif" height=100" /> <br/> <font color="AAAAAA">å•æ™ºèƒ½ä½“ Hover</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/drones/marl.gif" height=100" /> <br/> <font color="AAAAAA">å¤šæ™ºèƒ½ä½“ Hover</font>
</center> </td>
<td> <center>
<br/> <font color="AAAAAA">...</font>
</center> </td>
</tr>
</table>
</details>

### [MPE ç¯å¢ƒ](https://pettingzoo.farama.org/environments/mpe/)

<details open>
<summary>ï¼ˆç‚¹å‡»æ”¶èµ·/å±•å¼€ï¼‰</summary>

<table rules="none" align="center"><tr>
<td> <center>
<img src="docs/source/_static/figures/mpe/mpe_simple_push.gif" height=100" /><br/><font color="AAAAAA">Simple Push</font>
</center></td>
<td> <center>
<img src="docs/source/_static/figures/mpe/mpe_simple_reference.gif" height=100" /> <br/> <font color="AAAAAA">Simple Reference</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/mpe/mpe_simple_spread.gif" height=100" /> <br/> <font color="AAAAAA">Simple Spread</font>
</center> </td>
<td> <center>
<img src="docs/source/_static/figures/mpe/mpe_simple_adversary.gif" height=100" /> <br/> <font color="AAAAAA">Simple Adversary</font>
</center> </td>
<td> <center>
<br/> <font color="AAAAAA">...</font>
</center> </td>
</tr>
</table>

</details>

### [SMAC](https://github.com/oxwhirl/smac)

<div align="center">
<img src="docs/source/_static/figures/smac/smac.png" width="715" height="auto" align=center />
</div>

### [Google Research Football](https://github.com/google-research/football)

<div align="center">
<img src="docs/source/_static/figures/football/gfootball.png" width="720" height="auto" align=center />
</div>

## :point_right: å®‰è£…æ–¹æ³•

:computer: æœ¬åº“å¯åœ¨ Linuxã€Windowsã€MacOSã€EulerOS ç­‰å¤šç§ç³»ç»Ÿä¸Šè¿è¡Œã€‚

åœ¨å®‰è£… **XuanCe** ä¹‹å‰ï¼Œå»ºè®®å…ˆå®‰è£… [Anaconda](https://www.anaconda.com/download)ï¼Œä»¥ä¾¿å‡†å¤‡ä¸€ä¸ª Python ç¯å¢ƒã€‚ï¼ˆæ³¨ï¼šå¯ä»[**æ­¤å¤„**](https://repo.anaconda.com/archive/)é€‰æ‹©åˆé€‚ç‰ˆæœ¬çš„ Anacondaã€‚ï¼‰

å®‰è£…æ­¥éª¤å¦‚ä¸‹ï¼ˆåœ¨ç»ˆç«¯ / å‘½ä»¤è¡Œä¸‹æ‰§è¡Œï¼‰ï¼š

**æ­¥éª¤ 1**ï¼šåˆ›å»ºä¸€ä¸ªæ–°çš„ conda è™šæ‹Ÿç¯å¢ƒï¼ˆå»ºè®® python>=3.7ï¼‰ï¼š

```bash
conda create -n xuance_env python=3.7
```

**æ­¥éª¤ 2**ï¼šæ¿€æ´»è¯¥ç¯å¢ƒï¼š

```bash
conda activate xuance_env
```

**æ­¥éª¤ 3**ï¼šå®‰è£…æœ¬åº“ï¼š

```bash
pip install xuance
```

ä¸Šè¿°å‘½ä»¤ä¸åŒ…å«æ·±åº¦å­¦ä¹ æ¡†æ¶çš„ä¾èµ–ã€‚å¦‚æœéœ€è¦åŒæ—¶å®‰è£…ç‰¹å®šçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå¯é€šè¿‡ä»¥ä¸‹å‘½ä»¤ï¼š
- ä»…å®‰è£… PyTorch: pip install xuance[torch]
- ä»…å®‰è£… TensorFlow2: pip install xuance[tensorflow]
- ä»…å®‰è£… MindSpore: pip install xuance[mindspore]
- ä¸€æ¬¡æ€§å®‰è£…å…¨éƒ¨ä¾èµ–: pip install xuance[all]

æ³¨æ„ï¼šå¦‚æœè¿˜éœ€è¦ç”¨åˆ°å…¶ä»–åŠŸèƒ½æˆ–ç‰¹å®šçš„ä¾èµ–ï¼Œè¯·æ‰‹åŠ¨å®‰è£…ç›¸å…³åŒ…ã€‚

## :point_right: å¿«é€Ÿä¸Šæ‰‹

### è®­ç»ƒæ¨¡å‹

```python
import xuance

runner = xuance.get_runner(method='dqn',
                           env='classic_control',
                           env_id='CartPole-v1',
                           is_test=False)
runner.run()
```

### æµ‹è¯•æ¨¡å‹

```python
import xuance

runner_test = xuance.get_runner(method='dqn',
                                env='classic_control',
                                env_id='CartPole-v1',
                                is_test=True)
runner_test.run()
```

### å¯è§†åŒ–è®­ç»ƒç»“æœ

#### Tensorboard

å¯é€šè¿‡ Tensorboard å¯¹è®­ç»ƒè¿‡ç¨‹è¿›è¡Œå¯è§†åŒ–ã€‚è®­ç»ƒå®Œæˆåï¼Œæ—¥å¿—æ–‡ä»¶å°†è‡ªåŠ¨ä¿å­˜åˆ°â€œ.results/â€ç›®å½•ä¸­ã€‚ä½ å¯åœ¨ç»ˆç«¯è¾“å…¥ä»¥ä¸‹å‘½ä»¤è¿›è¡ŒæŸ¥çœ‹ï¼š

```bash
tensorboard --logdir ./logs/dqn/torch/CartPole-v0
```

<div align="center">
<img src="docs/source/_static/figures/log/tensorboard.png" width="700" height="auto" align=center />
</div>


#### Weights & Biases (wandb)

XuanCe åŒæ ·æ”¯æŒ Weights & Biases (wandb) å·¥å…·æ¥å¯è§†åŒ–ç»“æœã€‚
- å¦‚ä½•åœ¨çº¿ä½¿ç”¨ wandb? :arrow_right: https://github.com/wandb/wandb.git/
- å¦‚ä½•ç¦»çº¿ä½¿ç”¨ wandb? :arrow_right: https://github.com/wandb/server.git/

<div align="center">
<img src="docs/source/_static/figures/log/wandb.png" width="700" height="auto" align=center />
</div>


ç¤¾åŒºäº¤æµ
- GitHub issues: https://github.com/agi-brain/xuance/issues
- GitHub discussions: https://github.com/orgs/agi-brain/discussions
- Discord é‚€è¯·é“¾æ¥: https://discord.gg/HJn2TBQS7y
- Slack é‚€è¯·é“¾æ¥: https://join.slack.com/t/xuancerllib/
- QQ 1ç¾¤ï¼š552432695ï¼ˆå·²æ»¡ï¼‰
- QQ 2ç¾¤ï¼š153966755
- å¾®ä¿¡å…¬ä¼—å·ï¼šâ€œç„ç­– RLlibâ€

ï¼ˆæ³¨ï¼šä¹Ÿå¯åœ¨ Stack Overflow ä¸Šæé—®ã€‚ï¼‰

<details open>
<summary>ï¼ˆQQ ç¾¤ä¸å¾®ä¿¡å…¬ä¼—å·äºŒç»´ç ï¼‰</summary>


<table rules="none" align="center"><tr>
<td> <center>
<img src="docs/source/_static/figures/QQ_group.jpeg" width="150" height="auto" /><br/><font color="AAAAAA">QQ ç¾¤</font>
</center></td>
<td> <center>
<img src="docs/source/_static/figures/Official_Account.jpg" width="150" height="auto" /> <br/> <font color="AAAAAA">å¾®ä¿¡å…¬ä¼—å·</font>
</center> </td>
</tr>
</table>


</details>


[@TFBestPractices](https://twitter.com/TFBestPractices/status/1665770204398223361)

### å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶æˆ–å¼€å‘ä¸­ä½¿ç”¨äº† XuanCeï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```
@article{liu2023xuance,
  title={XuanCe: A Comprehensive and Unified Deep Reinforcement Learning Library},
  author={Liu, Wenzhang and Cai, Wenzhe and Jiang, Kun and Cheng, Guangran and Wang, Yuanda and Wang, Jiawei and Cao, Jingyu and Xu, Lele and Mu, Chaoxu and Sun, Changyin},
  journal={arXiv preprint arXiv:2312.16248},
  year={2023}
}
```