agent: "PPO_Clip"  # choice: PPO_Clip, PPO_KL
env_name: "Drones"
env_id: "CtrlAviary"  # choices: ['CtrlAviary', 'HoverAviary', 'VelocityAviary']
continuous: True
num_drones: 1
record: False
render: True
obstacles: True
max_episode_steps: 200
vectorize: "DummyVecEnv_Drone"
policy: "Gaussian_AC"  # choice: Gaussian_AC for continuous actions, Categorical_AC for discrete actions.
representation: "Basic_MLP"
runner: "DRL"

representation_hidden_size: [512,]
actor_hidden_size: [512,]
critic_hidden_size: [512,]
activation: "LeakyReLU"

seed: 79811
parallels: 1
running_steps: 1000000
n_steps: 256
n_epoch: 16
n_minibatch: 8
learning_rate: 0.0004

use_grad_clip: True

vf_coef: 0.25
ent_coef: 0.0
target_kl: 0.001  # for PPO_KL agent
clip_range: 0.2  # for PPO_Clip agent
clip_grad_norm: 0.5
gamma: 0.99
use_gae: True
gae_lambda: 0.95
use_advnorm: True

use_obsnorm: True
use_rewnorm: True
obsnorm_range: 5
rewnorm_range: 5

test_steps: 10000
eval_interval: 5000
test_episode: 5
log_dir: "./logs/ppo/"
model_dir: "./models/ppo/"
