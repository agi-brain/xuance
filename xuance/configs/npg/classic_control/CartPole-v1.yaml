agent: "NPG"
env_name: "Classic Control"
env_id: "CartPole-v1"
env_seed: 1  # The random seed of the environment.
representation: "Basic_MLP"
vectorize: "DummyVecEnv"
policy: "Categorical_AC"
learner: "NPG_Learner"
runner: "DRL"

representation_hidden_size: [128,]
actor_hidden_size: [128,]
critic_hidden_size: [128,]
critic_hidden_size: [128,]
activation: 'relu'
activation_action: 'tanh'

seed: 1
parallels: 10
running_steps: 300000
horizon_size: 256  # the horizon size for an environment, buffer_size = horizon_size * parallels.
n_epochs: 1
n_minibatch: 8
learning_rate: 0.0004

gamma: 0.98
use_gae: True
gae_lambda: 0.95
use_advnorm: True

use_grad_clip: True  # gradient normalization
clip_type: 1  # Gradient clip for Mindspore: 0: ms.ops.clip_by_value; 1: ms.nn.ClipByNorm()
grad_clip_norm: 0.5
use_actions_mask: False
use_obsnorm: True  # Whether to use observation normalization trick.
use_rewnorm: True  # Whether to use reward normalization trick.
obsnorm_range: 5
rewnorm_range: 5

test_steps: 10000
eval_interval: 50000
test_episode: 10
log_dir: "./logs/npg/"
model_dir: "./models/npg/"